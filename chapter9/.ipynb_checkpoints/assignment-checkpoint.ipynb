{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络及MNIST读入工具代码\n",
    "与上次实验一样，请直接跳过这部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    \"\"\"\n",
    "    对层的封装\n",
    "    存储权重矩阵w，偏置b，激活函数以及一些中间运算结果用于简化计算\n",
    "    \"\"\"\n",
    "    def __init__(self, d, n, act_fuc=\"tanh\"):\n",
    "        \"\"\"\n",
    "        初始化一层n个维数为d的神经元\n",
    "        Args:\n",
    "            n : 神经元个数\n",
    "            d : 神经元维数\n",
    "        \"\"\"\n",
    "        # 初始化权重矩阵，维度为d X n，每一列的d x 1向量代表一个神经元的w权重\n",
    "        self.w =0.1* np.random.randn(d, n)\n",
    "        # b 为 d x 1的偏置，且每一维度的值都相同，\n",
    "        # 这里初始化为1x1的随机数，计算时利用np的broadcast机制变成d x 1维度\n",
    "        self.b =0.1 * np.random.randn(1, 1)\n",
    "        # output存储该层经过激活函数输出的数值，是一个n x 1的向量\n",
    "        # 这里先初始化为0\n",
    "        self.output = 0\n",
    "        # v是未经过偏置和激活函数的数据\n",
    "        self.v = 0\n",
    "        # input记录输入该层的数据，是一个d x 1的向量\n",
    "        self.input = 0\n",
    "        # d记录该层的维数 n记录神经元个数\n",
    "        self.d = d\n",
    "        self.n = n\n",
    "        # 设置激活函数\n",
    "        self.act_fuc = act_fuc\n",
    "        # delta是下一层的E对该层输出的偏导数\n",
    "        self.delta = 0\n",
    "        \n",
    "    def forward_propagation(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        计算本层的输出，并更新input和output参数\n",
    "        Args:\n",
    "            x : 上一层输入的数据\n",
    "        \"\"\"\n",
    "        # 前向传播 x为 dx1 的列向量，有误抛出异常\n",
    "        if x.shape[0] != self.d:\n",
    "            raise RuntimeError(\"input's shape is not match with d\")\n",
    "        # 将input的值更新为x\n",
    "        self.input = x\n",
    "        # w 是d X n的矩阵，x是 d x 1的列向量\n",
    "        # w.T 为n x d 的矩阵，与x点积后，结果为 n x 1的列向量，\n",
    "        # 加上偏置后计算激活函数的输出，\n",
    "        self.v = np.dot(self.w.T, x)+self.b\n",
    "        self.output = self.active_function(self.v)   \n",
    "        # 更新output的值为激活函数的结果\n",
    "        return self.output\n",
    "    \n",
    "    def back_propagation_output(self, y):\n",
    "        \"\"\"\n",
    "        输出层的反向传播\n",
    "        Args:\n",
    "            y : 目标结果\n",
    "        \"\"\"\n",
    "        # y的维度为n x 1\n",
    "        if y.shape[0] != self.n:\n",
    "            raise RuntimeError(\"label's shape is not match with n\")\n",
    "        # delta为损失函数对该层输入的偏导\n",
    "        # 通过链式法则，delta为 -（损失函数对output的偏导） * （output对v的偏导）\n",
    "        self.delta = (y - self.output)*self.active_function_derivative(self.v)\n",
    "        # 得到的delta是 n x 1的向量\n",
    "        return self.delta\n",
    "    \n",
    "    def update_w(self):\n",
    "        \"\"\"\n",
    "        更新权重矩阵\n",
    "        \n",
    "        \"\"\"\n",
    "        # w的每一列都代表一个神经元的权重向量，对于每个神经元的权重，\n",
    "        # 更新时只计算与其有关系的delta元素和learning rate和input的乘积\n",
    "        for i in range(0, self.n):\n",
    "            self.w[:, i] += (self.delta[i]*lr*self.input.T).flatten()\n",
    "       \n",
    "    def back_propagation_hidden(self, next_delta, next_w):\n",
    "        \"\"\"\n",
    "        隐含层的反向传播\n",
    "        Args:\n",
    "            next_delta : 来自后面一层的delta值\n",
    "            next_w : 来自后面一层的w权重矩阵\n",
    "        \"\"\"\n",
    "        # 对于隐含层，总共的误差来自于后面一层所有的神经元，\n",
    "        # 需要计算后面一层的误差与本层每个神经元输出的偏导并且分别求和\n",
    "        # 使用点积next_w, next_delta计算出的矩阵就是满足需求的矩阵\n",
    "        # 然后与激活函数对输出求的偏导相乘得到结果\n",
    "        self.delta = np.dot(next_w, next_delta)*self.active_function_derivative(self.v)\n",
    "        return self.delta\n",
    "\n",
    "    def active_function(self, x):\n",
    "        \"\"\"\n",
    "        激活函数\n",
    "        Args:\n",
    "            x : 输入\n",
    "        \"\"\"\n",
    "        if self.act_fuc == \"tanh\":\n",
    "            return np.tanh(x)\n",
    "        elif self.act_fuc == \"sigmoid\":\n",
    "            return 1/(1+np.exp(-x))\n",
    "        elif self.act_fuc == \"relu\":\n",
    "            return (np.abs(x) + x) / 2\n",
    "\n",
    "    def active_function_derivative(self, x):\n",
    "        \"\"\"\n",
    "        激活函数的导数\n",
    "        Args:\n",
    "            x : 输入\n",
    "        \"\"\"\n",
    "        if self.act_fuc == \"tanh\":\n",
    "            return 1 - (self.active_function(x)**2)\n",
    "        elif self.act_fuc == \"sigmoid\":\n",
    "            return self.active_function(x)*(1-self.active_function(x))\n",
    "        elif self.act_fuc == \"relu\":\n",
    "            z = self.active_function(x)\n",
    "            z[z > 0] = 1 \n",
    "            return z\n",
    "\n",
    "class Network(object):\n",
    "    \"\"\"\n",
    "    对神经网络模型的封装\n",
    "    提供构建网络结构，训练，测试，绘制训练损失和准确率图方法\n",
    "    使用时首先初始化一个Network对象，然后使用add_layer(dim, num, act_fuc=\"\")方法添加网络层\n",
    "    注意\n",
    "        1. dim和前面层的神经元个数要一致\n",
    "        2. 激活函数目前只有tanh, sigmoid, relu ，默认为tanh\n",
    "    构建完成后，使用train方法进行训练。\n",
    "    训练数据data和标签y的维度应为d x n，其中 d 要与网络第一层的dim相同\n",
    "    其余参数说明参照train方法的注释\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        # 存储网络层\n",
    "        self.layers = []\n",
    "        # 记录训练时验证集的准确率\n",
    "        self.test_ac = []\n",
    "        # 记录训练时的loss\n",
    "        self.train_loss = []\n",
    "        \n",
    "    def add_layer(self, layer):\n",
    "        \"\"\"\n",
    "        增加网络层\n",
    "        Args:\n",
    "            layer : Layer对象\n",
    "        \"\"\"\n",
    "        self.layers.append(layer)\n",
    "        \n",
    "    def add_layer(self, dim, num, act_fuc=\"tanh\"):\n",
    "        \"\"\"\n",
    "        直接传参，增加网络层\n",
    "        Args:\n",
    "            dim : layer的维数\n",
    "            num : layer的神经元个数\n",
    "            act_fuc : layer的激活函数名\n",
    "        \"\"\"\n",
    "        self.layers.append(Layer(dim, num, act_fuc))\n",
    "        \n",
    "    def fp(self, x):\n",
    "        \"\"\"\n",
    "        对整个网络进行前向传播\n",
    "        Args:\n",
    "            x : 输入层的数据\n",
    "        Returns:\n",
    "            res : 输出层的结果\n",
    "        \"\"\"\n",
    "        for i in range(len(self.layers)):\n",
    "            # 输入层到隐藏层\n",
    "            if i == 0:\n",
    "                res = self.layers[i].forward_propagation(x)\n",
    "            # 非输入层到下一层的前向传播，输入的数据是上一层的结果\n",
    "            else:\n",
    "                res = self.layers[i].forward_propagation(res)\n",
    "        return res\n",
    "    \n",
    "    def bp(self, y):\n",
    "        \"\"\"\n",
    "        对整个网络进行反向传播\n",
    "        Args:\n",
    "            y : 输出层的目标数据\n",
    "        \"\"\"\n",
    "        # 反向传播\n",
    "        for i in range(len(self.layers)):\n",
    "            # 输出层的bp\n",
    "            if i == 0:\n",
    "                bp_res = self.layers[len(self.layers)-i-1].back_propagation_output(y)\n",
    "            # 隐藏层的bp\n",
    "            else:\n",
    "                bp_res = self.layers[len(self.layers)-i-1].\\\n",
    "                    back_propagation_hidden(bp_res, self.layers[len(self.layers)-i].w)\n",
    "        # 更新权重\n",
    "        for i in self.layers:\n",
    "            i.update_w()\n",
    "    \n",
    "    def train(self, iter_num, data, y, val_data=None, val_label=None, data_size=60000, show_num=500):\n",
    "        \"\"\"\n",
    "        模型训练\n",
    "        进行iter_num次迭代，每show_num次输出一次平均loss\n",
    "        当val_data不为None时，每show_num次进行一次验证集上的测试，输出验证集的准确率\n",
    "        Args:\n",
    "            iter_num : 迭代次数\n",
    "            data : 训练数据集，形状为 d x n ，即每个样本都是一个d维的列向量\n",
    "            y : 训练目标输出，形状为 output_n x n output_n是输出层的神经元个数\n",
    "            val_data : 验证集数据 \n",
    "            val_label : 验证集标签 维度为 1 x 验证集数据的样本数 注意这里是标签，与y不同，仅用于判断模型输出是否正确\n",
    "            data_size : 训练集的样本总数\n",
    "            show_num : 每多少轮迭代输出一次平均loss和测试结果\n",
    "        \"\"\"\n",
    "        loss = 0\n",
    "        self.show_num = show_num\n",
    "        # 迭代iter_num次\n",
    "        for j in range(iter_num+1):\n",
    "            # 前向传播\n",
    "            fp_res = self.fp(np.array([data[:,j % data_size]]).T)\n",
    "            # 反向传播\n",
    "            self.bp(np.array([y[:,j % data_size]]).T)\n",
    "            # 输出层的结果和y计算loss\n",
    "            loss += self.loss(fp_res, y[:,j % data_size])\n",
    "            if j % show_num == 0 and j > 0:\n",
    "                print(\"iter %d loss is %f\" % (j, loss/show_num)) \n",
    "                self.train_loss.append(loss/show_num)\n",
    "                loss = 0\n",
    "                if val_data is not None:\n",
    "                    ac = self.test(val_data, val_label)\n",
    "                    print(\"test accuracy is %f\" % (ac))  \n",
    "                    self.test_ac.append(ac)\n",
    "               \n",
    "    def inference(self, test_data):\n",
    "        \"\"\"\n",
    "        推断测试结果\n",
    "        Args:\n",
    "            test_data : 进行inference的测试数据\n",
    "        Returns:\n",
    "            inference的结果\n",
    "        \"\"\"\n",
    "        # 只进行前向传播\n",
    "        res = self.fp(test_data)\n",
    "        # print(\"test result is\",  fp_res)\n",
    "        return res\n",
    "    \n",
    "    def test_singe(self, test_data, y):\n",
    "        \"\"\"\n",
    "        测试一个样本的分类是否正确\n",
    "        Args:\n",
    "            test_data : 进行inference的测试数据\n",
    "            y ：标签，用于判断模型输出是否正确\n",
    "        Returns:\n",
    "            1 分类正确\n",
    "            0 分类错误\n",
    "        \"\"\"\n",
    "        res = self.fp(test_data)\n",
    "        res = np.argmax(res)\n",
    "        if res == y:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def test(self, test_data, labels):\n",
    "        \"\"\"\n",
    "        测试模型在测试集中的准确率\n",
    "        Args:\n",
    "            test_data : 进行inference的测试数据\n",
    "            labels : 测试集的标签\n",
    "        Returns:\n",
    "            0 - 1 之间的准确率\n",
    "        \"\"\"\n",
    "        # 只是计算正确分类的样本数/data_size\n",
    "        count = 0.0\n",
    "        data_size = len(test_data)\n",
    "        for i in range(data_size):\n",
    "            count = count+self.test_singe(np.array([test_data[:,i]]).T, labels[i])\n",
    "        return count/data_size\n",
    "    \n",
    "    def loss(self, y, yt):\n",
    "        \"\"\"\n",
    "        softmax loss函数\n",
    "        Args:\n",
    "            y : 输出数据\n",
    "            yt : ground-truth\n",
    "        Returns:\n",
    "            loss的值\n",
    "        \"\"\"\n",
    "        j = np.argmax(yt)\n",
    "        d = np.sum(np.exp(y))\n",
    "        u = np.exp(y.T.flatten()[j])\n",
    "        return -np.log(u/d)\n",
    "#         return np.sum(np.square(y-yt))/len(y)\n",
    "    \n",
    "    def draw_training_loss(self, title):\n",
    "        \"\"\"\n",
    "        绘制训练时的损失\n",
    "        Args:\n",
    "            title : 图表的标题\n",
    "        \"\"\"\n",
    "        self.draw_image(self.train_loss, title)\n",
    "        \n",
    "    def draw_training_ac(self, title):\n",
    "        \"\"\"\n",
    "        绘制训练时的验证准确率\n",
    "        Args:\n",
    "            title : 图表的标题\n",
    "        \"\"\"\n",
    "        self.draw_image(self.test_ac, title)\n",
    "        \n",
    "    def draw_image(self, y, title):\n",
    "        plt.title(title)\n",
    "        x = []\n",
    "        for i in range(len(y)):\n",
    "            x.append(i*self.show_num)\n",
    "        plt.plot(x, y)\n",
    "        plt.xlabel(\"iter_num\")\n",
    "        plt.show()\n",
    "\n",
    "# 训练集文件\n",
    "train_images_idx3_ubyte_file = 'F:/pythoncode/MachineLearning/chapter6/' \\\n",
    "                                'data/train-images-idx3-ubyte'\n",
    "                               \n",
    "# 训练集标签文件\n",
    "train_labels_idx1_ubyte_file = 'F:/pythoncode/MachineLearning/' \\\n",
    "                               'chapter6/data/train-labels-idx1-ubyte'\n",
    "\n",
    "# 测试集文件\n",
    "test_images_idx3_ubyte_file = 'F:/pythoncode/MachineLearning/' \\\n",
    "                               'chapter6/data/t10k-images-idx3-ubyte'\n",
    "# 测试集标签文件\n",
    "test_labels_idx1_ubyte_file = 'F:/pythoncode/MachineLearning/' \\\n",
    "                               'chapter6/data/t10k-labels-idx1-ubyte'\n",
    "\n",
    "\n",
    "def decode_idx3_ubyte(idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    解析idx3文件的通用函数\n",
    "    :param idx3_ubyte_file: idx3文件路径\n",
    "    :return: 数据集\n",
    "    \"\"\"\n",
    "    # 读取二进制数据\n",
    "    bin_data = open(idx3_ubyte_file, 'rb').read()\n",
    "\n",
    "    # 解析文件头信息，依次为魔数、图片数量、每张图片高、每张图片宽\n",
    "    offset = 0\n",
    "    fmt_header = '>iiii' #因为数据结构中前4行的数据类型都是32位整型，所以采用i格式，但我们需要读取前4行数据，所以需要4个i。我们后面会看到标签集中，只使用2个ii。\n",
    "    magic_number, num_images, num_rows, num_cols = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    # print('魔数:%d, 图片数量: %d张, 图片大小: %d*%d' % (magic_number, num_images, num_rows, num_cols))\n",
    "\n",
    "    # 解析数据集\n",
    "    image_size = num_rows * num_cols\n",
    "    offset += struct.calcsize(fmt_header)  #获得数据在缓存中的指针位置，从前面介绍的数据结构可以看出，读取了前4行之后，指针位置（即偏移位置offset）指向0016。\n",
    "    # print(offset)\n",
    "    fmt_image = '>' + str(image_size) + 'B'  #图像数据像素值的类型为unsigned char型，对应的format格式为B。这里还有加上图像大小784，是为了读取784个B格式数据，如果没有则只会读取一个值（即一副图像中的一个像素值）\n",
    "    # print(fmt_image,offset,struct.calcsize(fmt_image))\n",
    "    images = np.empty((num_images, num_rows, num_cols))\n",
    "    #plt.figure()\n",
    "    for i in range(num_images):\n",
    "        # if (i + 1) % 10000 == 0:\n",
    "        #     print('已解析 %d' % (i + 1) + '张')\n",
    "        #     print(offset)\n",
    "        images[i] = np.array(struct.unpack_from(fmt_image, bin_data, offset)).reshape((num_rows, num_cols))\n",
    "        #print(images[i])\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "#        plt.imshow(images[i],'gray')\n",
    "#        plt.pause(0.00001)\n",
    "#        plt.show()\n",
    "    #plt.show()\n",
    "\n",
    "    return images\n",
    "\n",
    "\n",
    "def decode_idx1_ubyte(idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    解析idx1文件的通用函数\n",
    "    :param idx1_ubyte_file: idx1文件路径\n",
    "    :return: 数据集\n",
    "    \"\"\"\n",
    "    # 读取二进制数据\n",
    "    bin_data = open(idx1_ubyte_file, 'rb').read()\n",
    "\n",
    "    # 解析文件头信息，依次为魔数和标签数\n",
    "    offset = 0\n",
    "    fmt_header = '>ii'\n",
    "    magic_number, num_images = struct.unpack_from(fmt_header, bin_data, offset)\n",
    "    # print('魔数:%d, 图片数量: %d张' % (magic_number, num_images))\n",
    "\n",
    "    # 解析数据集\n",
    "    offset += struct.calcsize(fmt_header)\n",
    "    fmt_image = '>B'\n",
    "    labels = np.empty(num_images)\n",
    "    for i in range(num_images):\n",
    "        # if (i + 1) % 10000 == 0:\n",
    "        #     print ('已解析 %d' % (i + 1) + '张')\n",
    "        labels[i] = struct.unpack_from(fmt_image, bin_data, offset)[0]\n",
    "        offset += struct.calcsize(fmt_image)\n",
    "    return labels\n",
    "\n",
    "\n",
    "def load_train_images(idx_ubyte_file=train_images_idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    TRAINING SET IMAGE FILE (train-images-idx3-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  60000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*row*col维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "\n",
    "\n",
    "def load_train_labels(idx_ubyte_file=train_labels_idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    TRAINING SET LABEL FILE (train-labels-idx1-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  60000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*1维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)\n",
    "\n",
    "\n",
    "def load_test_images(idx_ubyte_file=test_images_idx3_ubyte_file):\n",
    "    \"\"\"\n",
    "    TEST SET IMAGE FILE (t10k-images-idx3-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000803(2051) magic number\n",
    "    0004     32 bit integer  10000            number of images\n",
    "    0008     32 bit integer  28               number of rows\n",
    "    0012     32 bit integer  28               number of columns\n",
    "    0016     unsigned byte   ??               pixel\n",
    "    0017     unsigned byte   ??               pixel\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               pixel\n",
    "    Pixels are organized row-wise. Pixel values are 0 to 255. 0 means background (white), 255 means foreground (black).\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*row*col维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx3_ubyte(idx_ubyte_file)\n",
    "\n",
    "\n",
    "def load_test_labels(idx_ubyte_file=test_labels_idx1_ubyte_file):\n",
    "    \"\"\"\n",
    "    TEST SET LABEL FILE (t10k-labels-idx1-ubyte):\n",
    "    [offset] [type]          [value]          [description]\n",
    "    0000     32 bit integer  0x00000801(2049) magic number (MSB first)\n",
    "    0004     32 bit integer  10000            number of items\n",
    "    0008     unsigned byte   ??               label\n",
    "    0009     unsigned byte   ??               label\n",
    "    ........\n",
    "    xxxx     unsigned byte   ??               label\n",
    "    The labels values are 0 to 9.\n",
    "\n",
    "    :param idx_ubyte_file: idx文件路径\n",
    "    :return: n*1维np.array对象，n为图片数量\n",
    "    \"\"\"\n",
    "    return decode_idx1_ubyte(idx_ubyte_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据读入和预处理\n",
    "读入MNIST数据，进行归一化，使用bootstrap方法构建5个训练数据集\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据集\n",
    "train_images = load_train_images()\n",
    "train_labels = load_train_labels()\n",
    "# 测试集\n",
    "test_images = load_test_images()\n",
    "test_labels = load_test_labels()\n",
    "\n",
    "# 将训练集转换为 60000 x 784 测试集转换为 10000 x 784\n",
    "train_data = train_images.reshape((60000, 784))\n",
    "test_data = test_images.reshape((10000, 784))\n",
    "# mnist图片是灰度图，每个像素数据范围在0-255，对其做归一化预处理\n",
    "train_data = train_data/255\n",
    "test_data = test_data/255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用bootstrap构建5个新的数据集\n",
    "有放回地随机抽取原数据集中的样本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用bootstrap方法，构建6个60000样本的训练数据集\n",
    "# bootstrap_train数组存放构建的6个训练数据集，\n",
    "bootstrap_train = []\n",
    "# bootstrap_labels存放训练集对应的标签\n",
    "bootstrap_labels = []\n",
    "# 循环5次构建5个数据集\n",
    "for i in range(5):\n",
    "    tmp_train = []\n",
    "    tmp_labels = []\n",
    "    for j in range(60000):\n",
    "        # 随机抽取数据\n",
    "        pos = random.randint(1, 60000)-1\n",
    "        tmp_train.append(train_data[pos])\n",
    "        tmp_labels.append(train_labels[pos])\n",
    "       \n",
    "    bootstrap_train.append(np.array(tmp_train))\n",
    "    bootstrap_labels.append(np.array(tmp_labels))\n",
    "    \n",
    "bootstrap_train = np.array(bootstrap_train)\n",
    "bootstrap_labels = np.array(bootstrap_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型1 ： 径向基SVM\n",
    "Sklearn框架提供了很多机器学习领域的方法实现，所以我选择这个框架来构建SVM  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 参数 decision_function_shape='ovr'用于设置svm通过对每个类别分别训练一个分类器实现多分类\n",
    "model1 = svm.SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "model1.fit(bootstrap_train[0], bootstrap_labels[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF-SVM's accuracy 0.943900\n"
     ]
    }
   ],
   "source": [
    "# 训练的结果是\n",
    "count = 0.0\n",
    "for i in range(10000):\n",
    "    if model1.predict([test_data[i]])[0] == test_labels[i]:\n",
    "        count += 1\n",
    "print(\"RBF-SVM's accuracy %f\"%(count/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型2 ： 线性核SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='linear',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = svm.SVC(kernel='linear', decision_function_shape='ovr')\n",
    "model2.fit(bootstrap_train[1], bootstrap_labels[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear-SVM's accuracy 0.934100\n"
     ]
    }
   ],
   "source": [
    "# 训练的结果是\n",
    "count = 0.0\n",
    "for i in range(10000):\n",
    "    if model2.predict([test_data[i]])[0] == test_labels[i]:\n",
    "        count += 1\n",
    "print(\"Linear-SVM's accuracy %f\"%(count/10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型3 ：3层神经网络\n",
    "使用上次实验完成的bp神经网络代码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理 将标签转换为one hot\n",
    "y3 = []\n",
    "for i in range(60000):\n",
    "    item = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    item[int(bootstrap_labels[2][i])] = 1 \n",
    "    y3.append(item)\n",
    "# y的形状为10 x 60000\n",
    "y3 = np.array(y3).T  \n",
    "x3 = bootstrap_train[2].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5000 loss is 1.575112\n",
      "test accuracy is 0.932398\n",
      "iter 10000 loss is 1.575536\n",
      "test accuracy is 0.936224\n",
      "iter 15000 loss is 1.573246\n",
      "test accuracy is 0.940051\n",
      "iter 20000 loss is 1.567093\n",
      "test accuracy is 0.936224\n",
      "iter 25000 loss is 1.581872\n",
      "test accuracy is 0.933673\n",
      "iter 30000 loss is 1.574088\n",
      "test accuracy is 0.932398\n",
      "iter 35000 loss is 1.574341\n",
      "test accuracy is 0.941327\n",
      "iter 40000 loss is 1.575071\n",
      "test accuracy is 0.936224\n",
      "iter 45000 loss is 1.572757\n",
      "test accuracy is 0.932398\n",
      "iter 50000 loss is 1.569452\n",
      "test accuracy is 0.938776\n",
      "iter 55000 loss is 1.574952\n",
      "test accuracy is 0.933673\n",
      "iter 60000 loss is 1.570423\n",
      "test accuracy is 0.933673\n",
      "iter 65000 loss is 1.571580\n",
      "test accuracy is 0.940051\n",
      "iter 70000 loss is 1.573151\n",
      "test accuracy is 0.938776\n",
      "iter 75000 loss is 1.570571\n",
      "test accuracy is 0.938776\n",
      "iter 80000 loss is 1.564454\n",
      "test accuracy is 0.936224\n",
      "iter 85000 loss is 1.578603\n",
      "test accuracy is 0.937500\n",
      "iter 90000 loss is 1.570940\n",
      "test accuracy is 0.936224\n",
      "iter 95000 loss is 1.571213\n",
      "test accuracy is 0.942602\n",
      "iter 100000 loss is 1.571658\n",
      "test accuracy is 0.936224\n",
      "iter 105000 loss is 1.569710\n",
      "test accuracy is 0.942602\n",
      "iter 110000 loss is 1.566535\n",
      "test accuracy is 0.938776\n",
      "iter 115000 loss is 1.572056\n",
      "test accuracy is 0.936224\n",
      "iter 120000 loss is 1.567256\n",
      "test accuracy is 0.933673\n",
      "iter 125000 loss is 1.568530\n",
      "test accuracy is 0.942602\n",
      "iter 130000 loss is 1.570575\n",
      "test accuracy is 0.940051\n",
      "iter 135000 loss is 1.567730\n",
      "test accuracy is 0.938776\n",
      "iter 140000 loss is 1.561800\n",
      "test accuracy is 0.938776\n",
      "iter 145000 loss is 1.575471\n",
      "test accuracy is 0.941327\n",
      "iter 150000 loss is 1.567828\n",
      "test accuracy is 0.940051\n",
      "iter 155000 loss is 1.568427\n",
      "test accuracy is 0.942602\n",
      "iter 160000 loss is 1.568886\n",
      "test accuracy is 0.937500\n",
      "iter 165000 loss is 1.566850\n",
      "test accuracy is 0.942602\n",
      "iter 170000 loss is 1.563974\n",
      "test accuracy is 0.938776\n",
      "iter 175000 loss is 1.569364\n",
      "test accuracy is 0.938776\n",
      "iter 180000 loss is 1.564500\n",
      "test accuracy is 0.933673\n",
      "iter 185000 loss is 1.565701\n",
      "test accuracy is 0.940051\n",
      "iter 190000 loss is 1.568383\n",
      "test accuracy is 0.940051\n",
      "iter 195000 loss is 1.565300\n",
      "test accuracy is 0.940051\n",
      "iter 200000 loss is 1.559669\n",
      "test accuracy is 0.942602\n",
      "iter 205000 loss is 1.572867\n",
      "test accuracy is 0.941327\n",
      "iter 210000 loss is 1.565384\n",
      "test accuracy is 0.940051\n",
      "iter 215000 loss is 1.565901\n",
      "test accuracy is 0.942602\n",
      "iter 220000 loss is 1.566470\n",
      "test accuracy is 0.940051\n",
      "iter 225000 loss is 1.564154\n",
      "test accuracy is 0.943878\n",
      "iter 230000 loss is 1.561467\n",
      "test accuracy is 0.940051\n",
      "iter 235000 loss is 1.567020\n",
      "test accuracy is 0.937500\n",
      "iter 240000 loss is 1.561865\n",
      "test accuracy is 0.936224\n",
      "iter 245000 loss is 1.563551\n",
      "test accuracy is 0.940051\n",
      "iter 250000 loss is 1.566307\n",
      "test accuracy is 0.940051\n",
      "iter 255000 loss is 1.563249\n",
      "test accuracy is 0.940051\n",
      "iter 260000 loss is 1.557445\n",
      "test accuracy is 0.942602\n",
      "iter 265000 loss is 1.570415\n",
      "test accuracy is 0.941327\n",
      "iter 270000 loss is 1.563005\n",
      "test accuracy is 0.943878\n",
      "iter 275000 loss is 1.563444\n",
      "test accuracy is 0.941327\n",
      "iter 280000 loss is 1.564170\n",
      "test accuracy is 0.941327\n",
      "iter 285000 loss is 1.561763\n",
      "test accuracy is 0.945153\n",
      "iter 290000 loss is 1.559331\n",
      "test accuracy is 0.942602\n",
      "iter 295000 loss is 1.565031\n",
      "test accuracy is 0.938776\n",
      "iter 300000 loss is 1.559789\n",
      "test accuracy is 0.938776\n",
      "iter 305000 loss is 1.561330\n",
      "test accuracy is 0.943878\n",
      "iter 310000 loss is 1.564517\n",
      "test accuracy is 0.941327\n",
      "iter 315000 loss is 1.561549\n",
      "test accuracy is 0.938776\n",
      "iter 320000 loss is 1.555555\n",
      "test accuracy is 0.942602\n",
      "iter 325000 loss is 1.568310\n",
      "test accuracy is 0.942602\n",
      "iter 330000 loss is 1.560929\n",
      "test accuracy is 0.943878\n",
      "iter 335000 loss is 1.561403\n",
      "test accuracy is 0.943878\n",
      "iter 340000 loss is 1.562108\n",
      "test accuracy is 0.943878\n",
      "iter 345000 loss is 1.559765\n",
      "test accuracy is 0.946429\n",
      "iter 350000 loss is 1.557243\n",
      "test accuracy is 0.943878\n",
      "iter 355000 loss is 1.562973\n",
      "test accuracy is 0.941327\n",
      "iter 360000 loss is 1.557521\n",
      "test accuracy is 0.940051\n",
      "iter 365000 loss is 1.559414\n",
      "test accuracy is 0.941327\n",
      "iter 370000 loss is 1.562642\n",
      "test accuracy is 0.942602\n",
      "iter 375000 loss is 1.559585\n",
      "test accuracy is 0.940051\n",
      "iter 380000 loss is 1.554017\n",
      "test accuracy is 0.946429\n",
      "iter 385000 loss is 1.566301\n",
      "test accuracy is 0.941327\n",
      "iter 390000 loss is 1.559169\n",
      "test accuracy is 0.945153\n",
      "iter 395000 loss is 1.559565\n",
      "test accuracy is 0.945153\n",
      "iter 400000 loss is 1.560160\n",
      "test accuracy is 0.945153\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 学习率\n",
    "lr = 0.001\n",
    "# 模型构建\n",
    "model3 = Network()\n",
    "model3.add_layer(784, 28, act_fuc=\"relu\")\n",
    "model3.add_layer(28, 10, act_fuc=\"relu\")\n",
    "# 训练\n",
    "model3.train(400000, x3, y3,val_data=test_data.T, val_label=test_labels, show_num=5000)\n",
    "model3.draw_training_loss(\"model3 loss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model3's accuracy 0.9094387755102041\n"
     ]
    }
   ],
   "source": [
    "print(\"3-Layers-NN's accuracy\", model3.test(test_data.T, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型4 ：5层神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据预处理 将标签转换为one hot\n",
    "y4 = []\n",
    "for i in range(60000):\n",
    "    item = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    item[int(bootstrap_labels[3][i])] = 1 \n",
    "    y4.append(item)\n",
    "# y的形状为10 x 60000\n",
    "y4 = np.array(y4).T  \n",
    "x4 = bootstrap_train[3].T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5000 loss is 1.575129\n",
      "test accuracy is 0.933673\n",
      "iter 10000 loss is 1.567189\n",
      "test accuracy is 0.934949\n",
      "iter 15000 loss is 1.566782\n",
      "test accuracy is 0.929847\n",
      "iter 20000 loss is 1.569394\n",
      "test accuracy is 0.931122\n",
      "iter 25000 loss is 1.576312\n",
      "test accuracy is 0.932398\n",
      "iter 30000 loss is 1.566604\n",
      "test accuracy is 0.934949\n",
      "iter 35000 loss is 1.567472\n",
      "test accuracy is 0.936224\n",
      "iter 40000 loss is 1.562875\n",
      "test accuracy is 0.934949\n",
      "iter 45000 loss is 1.568058\n",
      "test accuracy is 0.932398\n",
      "iter 50000 loss is 1.574369\n",
      "test accuracy is 0.932398\n",
      "iter 55000 loss is 1.567411\n",
      "test accuracy is 0.931122\n",
      "iter 60000 loss is 1.570191\n",
      "test accuracy is 0.941327\n",
      "iter 65000 loss is 1.567539\n",
      "test accuracy is 0.940051\n",
      "iter 70000 loss is 1.561361\n",
      "test accuracy is 0.937500\n",
      "iter 75000 loss is 1.561933\n",
      "test accuracy is 0.936224\n",
      "iter 80000 loss is 1.564040\n",
      "test accuracy is 0.934949\n",
      "iter 85000 loss is 1.570655\n",
      "test accuracy is 0.933673\n",
      "iter 90000 loss is 1.560312\n",
      "test accuracy is 0.938776\n",
      "iter 95000 loss is 1.561441\n",
      "test accuracy is 0.936224\n",
      "iter 100000 loss is 1.557596\n",
      "test accuracy is 0.938776\n",
      "iter 105000 loss is 1.561927\n",
      "test accuracy is 0.937500\n",
      "iter 110000 loss is 1.568535\n",
      "test accuracy is 0.931122\n",
      "iter 115000 loss is 1.562081\n",
      "test accuracy is 0.934949\n",
      "iter 120000 loss is 1.565056\n",
      "test accuracy is 0.942602\n",
      "iter 125000 loss is 1.562197\n",
      "test accuracy is 0.941327\n",
      "iter 130000 loss is 1.556211\n",
      "test accuracy is 0.943878\n",
      "iter 135000 loss is 1.557214\n",
      "test accuracy is 0.941327\n",
      "iter 140000 loss is 1.559085\n",
      "test accuracy is 0.940051\n",
      "iter 145000 loss is 1.565366\n",
      "test accuracy is 0.937500\n",
      "iter 150000 loss is 1.555009\n",
      "test accuracy is 0.942602\n",
      "iter 155000 loss is 1.556305\n",
      "test accuracy is 0.940051\n",
      "iter 160000 loss is 1.552832\n",
      "test accuracy is 0.942602\n",
      "iter 165000 loss is 1.557362\n",
      "test accuracy is 0.937500\n",
      "iter 170000 loss is 1.563672\n",
      "test accuracy is 0.937500\n",
      "iter 175000 loss is 1.557401\n",
      "test accuracy is 0.936224\n",
      "iter 180000 loss is 1.560245\n",
      "test accuracy is 0.942602\n",
      "iter 185000 loss is 1.557931\n",
      "test accuracy is 0.941327\n",
      "iter 190000 loss is 1.551921\n",
      "test accuracy is 0.942602\n",
      "iter 195000 loss is 1.553071\n",
      "test accuracy is 0.945153\n",
      "iter 200000 loss is 1.554948\n",
      "test accuracy is 0.941327\n",
      "iter 205000 loss is 1.561179\n",
      "test accuracy is 0.941327\n",
      "iter 210000 loss is 1.549977\n",
      "test accuracy is 0.941327\n",
      "iter 215000 loss is 1.552279\n",
      "test accuracy is 0.942602\n",
      "iter 220000 loss is 1.549014\n",
      "test accuracy is 0.943878\n",
      "iter 225000 loss is 1.552949\n",
      "test accuracy is 0.941327\n",
      "iter 230000 loss is 1.559121\n",
      "test accuracy is 0.938776\n",
      "iter 235000 loss is 1.553528\n",
      "test accuracy is 0.937500\n",
      "iter 240000 loss is 1.556202\n",
      "test accuracy is 0.942602\n",
      "iter 245000 loss is 1.553824\n",
      "test accuracy is 0.940051\n",
      "iter 250000 loss is 1.548254\n",
      "test accuracy is 0.943878\n",
      "iter 255000 loss is 1.549334\n",
      "test accuracy is 0.946429\n",
      "iter 260000 loss is 1.551100\n",
      "test accuracy is 0.941327\n",
      "iter 265000 loss is 1.557505\n",
      "test accuracy is 0.943878\n",
      "iter 270000 loss is 1.545838\n",
      "test accuracy is 0.941327\n",
      "iter 275000 loss is 1.548261\n",
      "test accuracy is 0.938776\n",
      "iter 280000 loss is 1.545225\n",
      "test accuracy is 0.945153\n",
      "iter 285000 loss is 1.549225\n",
      "test accuracy is 0.943878\n",
      "iter 290000 loss is 1.555511\n",
      "test accuracy is 0.946429\n",
      "iter 295000 loss is 1.550230\n",
      "test accuracy is 0.942602\n",
      "iter 300000 loss is 1.552125\n",
      "test accuracy is 0.941327\n",
      "iter 305000 loss is 1.550425\n",
      "test accuracy is 0.943878\n",
      "iter 310000 loss is 1.545032\n",
      "test accuracy is 0.943878\n",
      "iter 315000 loss is 1.546156\n",
      "test accuracy is 0.945153\n",
      "iter 320000 loss is 1.547421\n",
      "test accuracy is 0.945153\n",
      "iter 325000 loss is 1.554009\n",
      "test accuracy is 0.945153\n",
      "iter 330000 loss is 1.542390\n",
      "test accuracy is 0.940051\n",
      "iter 335000 loss is 1.545041\n",
      "test accuracy is 0.943878\n",
      "iter 340000 loss is 1.541769\n",
      "test accuracy is 0.945153\n",
      "iter 345000 loss is 1.545624\n",
      "test accuracy is 0.942602\n",
      "iter 350000 loss is 1.551552\n",
      "test accuracy is 0.945153\n",
      "iter 355000 loss is 1.547522\n",
      "test accuracy is 0.941327\n",
      "iter 360000 loss is 1.548605\n",
      "test accuracy is 0.942602\n",
      "iter 365000 loss is 1.547572\n",
      "test accuracy is 0.943878\n",
      "iter 370000 loss is 1.542102\n",
      "test accuracy is 0.943878\n",
      "iter 375000 loss is 1.543080\n",
      "test accuracy is 0.946429\n",
      "iter 380000 loss is 1.544233\n",
      "test accuracy is 0.947704\n",
      "iter 385000 loss is 1.550508\n",
      "test accuracy is 0.945153\n",
      "iter 390000 loss is 1.539114\n",
      "test accuracy is 0.945153\n",
      "iter 395000 loss is 1.542310\n",
      "test accuracy is 0.945153\n",
      "iter 400000 loss is 1.538630\n",
      "test accuracy is 0.945153\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Layers-NN's accuracy 0.9451530612244898\n"
     ]
    }
   ],
   "source": [
    "# 学习率\n",
    "lr = 0.001\n",
    "# 模型构建\n",
    "model4 = Network()\n",
    "model4.add_layer(784, 28, act_fuc=\"relu\")\n",
    "model4.add_layer(28, 28, act_fuc=\"relu\")\n",
    "model4.add_layer(28, 28, act_fuc=\"relu\")\n",
    "model4.add_layer(28, 10, act_fuc=\"relu\")\n",
    "# 训练\n",
    "model4.train(400000, x4, y4, val_data=test_data.T, val_label=test_labels, show_num=5000)\n",
    "model4.draw_training_loss(\"model4 loss\")\n",
    "print(\"5-Layers-NN's accuracy\", model4.test(test_data.T, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型5 ：最近质心分类器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nearest Centroid's accuracy 0.818400\n"
     ]
    }
   ],
   "source": [
    "model5 = NearestCentroid()\n",
    "model5.fit(bootstrap_train[4], bootstrap_labels[4])\n",
    "# 训练的结果是\n",
    "count = 0.0\n",
    "for i in range(10000):\n",
    "    if model5.predict([test_data[i]])[0] == test_labels[i]:\n",
    "        count += 1\n",
    "print(\"Nearest Centroid's accuracy %f\"%(count/10000))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 集成学习\n",
    "每个模型进行投票表决"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1000 accuracy 0.942000\n",
      "iter 2000 accuracy 0.933500\n",
      "iter 3000 accuracy 0.932333\n",
      "iter 4000 accuracy 0.932250\n",
      "iter 5000 accuracy 0.930400\n",
      "iter 6000 accuracy 0.936667\n",
      "iter 7000 accuracy 0.940000\n",
      "iter 8000 accuracy 0.945250\n",
      "iter 9000 accuracy 0.949444\n",
      "iter 10000 accuracy 0.949500\n",
      "Final accuracy 0.949500\n"
     ]
    }
   ],
   "source": [
    "# 集成学习结果，每种模型等权重投票\n",
    "count = 0.0\n",
    "for i in range(10000):\n",
    "    res = np.zeros(10)\n",
    "    res[int(model1.predict([test_data[i]])[0])] += 1\n",
    "    res[int(model2.predict([test_data[i]])[0])] += 1\n",
    "    res[int(np.argmax(model3.inference(np.array([test_data[i]]).T)))] += 1\n",
    "    res[int(np.argmax(model4.inference(np.array([test_data[i]]).T)))] += 1\n",
    "    res[int(model5.predict([test_data[i]])[0])] += 1\n",
    "    if np.argmax(res) == test_labels[i]:\n",
    "        count += 1\n",
    "    if (i+1)%1000==0:\n",
    "        print(\"iter %d accuracy %f\"%(i+1,count/(i+1)))\n",
    "print(\"Final accuracy %f\"%(count/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1000 accuracy 0.946000\n",
      "iter 2000 accuracy 0.940000\n",
      "iter 3000 accuracy 0.937000\n",
      "iter 4000 accuracy 0.937000\n",
      "iter 5000 accuracy 0.935000\n",
      "iter 6000 accuracy 0.940500\n",
      "iter 7000 accuracy 0.943429\n",
      "iter 8000 accuracy 0.948000\n",
      "iter 9000 accuracy 0.951778\n",
      "iter 10000 accuracy 0.951600\n",
      "Final accuracy 0.951600\n"
     ]
    }
   ],
   "source": [
    "# 集成学习结果，每种模型等权重投票\n",
    "count = 0.0\n",
    "for i in range(10000):\n",
    "    res = np.zeros(10)\n",
    "    res[int(model1.predict([test_data[i]])[0])] += 1\n",
    "    res[int(model2.predict([test_data[i]])[0])] += 1\n",
    "    res[int(np.argmax(model3.inference(np.array([test_data[i]]).T)))] += 1\n",
    "    res[int(np.argmax(model4.inference(np.array([test_data[i]]).T)))] += 1\n",
    "#     res[int(model5.predict([test_data[i]])[0])] += 1\n",
    "    if np.argmax(res) == test_labels[i]:\n",
    "        count += 1\n",
    "    if (i+1)%1000==0:\n",
    "        print(\"iter %d accuracy %f\"%(i+1,count/(i+1)))\n",
    "print(\"Final accuracy %f\"%(count/10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
