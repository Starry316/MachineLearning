{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    res = 1+np.exp(-x)\n",
    "    return 1/res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    return np.exp(-x)/((1+np.exp(-x))**2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cell(object):\n",
    "    def __init__(self, d):\n",
    "        self.w = np.random.rand(d)\n",
    "        self.b = np.random.rand(1)\n",
    "        self.input = 0\n",
    "        self.output = 0\n",
    "        self.E = 0\n",
    "        self.old_w = self.w\n",
    "        \n",
    "    def front_pass(self, x):\n",
    "        self.input = x.flatten()\n",
    "        self.output = sigmoid(np.dot(self.w.T, x)+self.b)\n",
    "        return self.output\n",
    "    \n",
    "    def update_W(self, e):\n",
    "        self.old_w = self.w\n",
    "        self.w = self.w - lr * e\n",
    "    \n",
    "    def bp_output(self, y):\n",
    "        deta = -(y - self.output)*self.output*(1-self.output)*self.input\n",
    "        self.E = -(y - self.output)*self.output*(1-self.output)\n",
    "        self.update_W(deta)\n",
    "        return self.E\n",
    "        \n",
    "    def bp_hidden(self, es, w):\n",
    "        e_total = 0\n",
    "        for i in w:\n",
    "            for j in es:\n",
    "                e_total = e_total + i*j\n",
    "        self.E = e_total*self.output*(1-self.output)\n",
    "        deta = np.multiply(self.E, self.input)\n",
    "        self.update_W(deta)\n",
    "        return deta\n",
    "    \n",
    "        \n",
    "def L2_loss(y, yt):\n",
    "    y.flatten()\n",
    "    return np.sum(np.square(y-yt))    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = Cell(2)\n",
    "h2 = Cell(2)\n",
    "\n",
    "g1 = Cell(2)\n",
    "g2 = Cell(2)\n",
    "g3 = Cell(2)\n",
    "\n",
    "o1 = Cell(3)\n",
    "\n",
    "# layer1 = [h1, h2]\n",
    "# layer2 = [o1, o2]\n",
    "data = np.array([[0, 0],\n",
    "                [0, 1],\n",
    "                [1, 0],\n",
    "                [1, 1]])\n",
    "\n",
    "y = np.array([0,1,1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(100000):\n",
    "    for i in range(4):\n",
    "        oh1 = h1.front_pass(data[i])\n",
    "        oh2 = h2.front_pass(data[i])\n",
    "        \n",
    "        x1 = np.array([oh1, oh2])\n",
    "        # print(\"x1\",x1)\n",
    "        og1 = g1.front_pass(x1)\n",
    "        og2 = g2.front_pass(x1)\n",
    "        og3 = g3.front_pass(x1)\n",
    "   \n",
    "        x2 = np.array([og1, og2, og3])\n",
    "        # print(\"x2\",x2)\n",
    "        oo1 = o1.front_pass(x2)\n",
    "       \n",
    "        if j % 5000 == 0:\n",
    "            print(\"iter %d %f loss is %f\"%(j,oo1,L2_loss(oo1, y[i])))\n",
    "\n",
    "        oe1 = o1.bp_output(y[i])\n",
    "        \n",
    "        \n",
    "        # Es = np.array(e1)\n",
    "        \n",
    "        ge1 = g1.bp_hidden(oe1,[o1.old_w[0]])\n",
    "        ge2 = g2.bp_hidden(oe1,[o1.old_w[1]])\n",
    "        ge3 = g3.bp_hidden(oe1,[o1.old_w[2]])\n",
    "        \n",
    "        ge = [ge1,ge2,ge3]\n",
    "        w1 = [g1.old_w[0],g2.old_w[0],g3.old_w[0]]\n",
    "        w2 = [g1.old_w[1],g2.old_w[1],g3.old_w[1]]\n",
    "        he1 = h1.bp_hidden(ge, w1)\n",
    "        he2 = h2.bp_hidden(ge, w2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    # n 是神经元个数 d 是神经元维数\n",
    "    def __init__(self, n, d):\n",
    "        # 初始化n个神经元\n",
    "        cells = []\n",
    "        for i in range(n):\n",
    "            cells.append(Cell(d))\n",
    "        self.cells = cells\n",
    "        self.n = n\n",
    "        self.d = d\n",
    "        \n",
    "    def forward_propagation(self, x):\n",
    "        res = []\n",
    "        for i in range(self.n):\n",
    "            res.append(self.cells[i].front_pass(x))\n",
    "        return np.array(res)\n",
    "    \n",
    "    def back_propagation_output(self, y):\n",
    "        # y的维数应该和n相同\n",
    "        res = []\n",
    "        for i in range(self.n):\n",
    "            res.append(self.cells[i].bp_output(y[i]))\n",
    "        return np.array(res)\n",
    "    \n",
    "    def back_propagation_hidden(self, e, w):\n",
    "        # y的维数应该和n相同\n",
    "        w = w.T\n",
    "        # print(\"bph w \",w)\n",
    "        res = []\n",
    "        for i in range(self.n):\n",
    "            res.append(self.cells[i].bp_hidden(e, w[i]))\n",
    "        return np.array(res)\n",
    "    \n",
    "    def get_w(self):\n",
    "        res = []\n",
    "        for i in self.cells:\n",
    "            res.append(i.old_w)\n",
    "        return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer(2, 2)\n",
    "layer2 = Layer(3, 2)\n",
    "layer3 = Layer(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 0.000000 loss is 0.000000\niter 0 0.612862 loss is 0.149876\niter 0 0.612638 loss is 0.150049\niter 0 0.022298 loss is 0.000497\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5000 0.000000 loss is 0.000000\niter 5000 0.612845 loss is 0.149889\niter 5000 0.612624 loss is 0.150061\niter 5000 0.018695 loss is 0.000350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10000 0.000000 loss is 0.000000\niter 10000 0.612901 loss is 0.149846\niter 10000 0.612688 loss is 0.150011\niter 10000 0.018306 loss is 0.000335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 15000 0.000000 loss is 0.000000\niter 15000 0.612953 loss is 0.149805\niter 15000 0.612747 loss is 0.149965\niter 15000 0.017936 loss is 0.000322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20000 0.000000 loss is 0.000000\niter 20000 0.613002 loss is 0.149768\niter 20000 0.612803 loss is 0.149922\niter 20000 0.017584 loss is 0.000309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 25000 0.000000 loss is 0.000000\niter 25000 0.613047 loss is 0.149733\niter 25000 0.612855 loss is 0.149881\niter 25000 0.017251 loss is 0.000298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30000 0.000000 loss is 0.000000\niter 30000 0.613090 loss is 0.149700\niter 30000 0.612904 loss is 0.149844\niter 30000 0.016935 loss is 0.000287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 35000 0.000000 loss is 0.000000\niter 35000 0.613129 loss is 0.149669\niter 35000 0.612949 loss is 0.149808\niter 35000 0.016635 loss is 0.000277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40000 0.000000 loss is 0.000000\niter 40000 0.613167 loss is 0.149640\niter 40000 0.612992 loss is 0.149775\niter 40000 0.016349 loss is 0.000267\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 45000 0.000000 loss is 0.000000\niter 45000 0.613202 loss is 0.149613\niter 45000 0.613032 loss is 0.149744\niter 45000 0.016077 loss is 0.000258\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 50000 0.000000 loss is 0.000000\niter 50000 0.613235 loss is 0.149587\niter 50000 0.613070 loss is 0.149714\niter 50000 0.015817 loss is 0.000250\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for j in range(100000):\n",
    "    for i in range(4):\n",
    "        fo1 = layer1.forward_propagation(data[i])\n",
    "        fo2 = layer2.forward_propagation(fo1)\n",
    "        fo3 = layer3.forward_propagation(fo2)\n",
    "        \n",
    "        if j % 5000 == 0:\n",
    "            print(\"iter %d %f loss is %f\"%(j,fo3,L2_loss(fo3, y[i])))\n",
    "        \n",
    "        be3 = layer3.back_propagation_output([y[i]])\n",
    "        ow3 = layer3.get_w()\n",
    "        \n",
    "        be2 = layer2.back_propagation_hidden(be3, ow3)\n",
    "        ow2 = layer2.get_w()\n",
    "        \n",
    "        be1 = layer1.back_propagation_hidden(be2, ow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(iter_num, layers, data_size=4, lr = 1, show_num = 5000):\n",
    "    loss = 0\n",
    "    for j in range(iter_num):\n",
    "        # 现在没有对inputdata做封装\n",
    "        for i in range(len(layers)):\n",
    "            if i == 0:\n",
    "                fp_res = layers[i].forward_propagation(data[j%data_size])\n",
    "            else:\n",
    "                fp_res = layers[i].forward_propagation(fp_res)\n",
    "            if i == len(layers)-1:\n",
    "                loss = loss+L2_loss(fp_res, y[j % data_size])\n",
    "                if j % show_num == 0 :\n",
    "                    print(\"iter %d loss is %f\" % (j, loss/show_num))\n",
    "                    loss = 0\n",
    "        for i in range(len(layers)):\n",
    "            if i == 0:\n",
    "                bp_res = layers[len(layers)-i-1].back_propagation_output([y[j % data_size]])\n",
    "            else:\n",
    "                bp_res = layers[len(layers)-i-1].back_propagation_hidden(bp_res, old_w)\n",
    "            old_w = layers[len(layers)-i-1].get_w()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(layers, test_data):\n",
    "    fp_res = 0\n",
    "    for i in range(len(layers)):\n",
    "            if i == 0:\n",
    "                fp_res = layers[i].forward_propagation(test_data)\n",
    "            else:\n",
    "                fp_res = layers[i].forward_propagation(fp_res)\n",
    "    print(\"test result is\",fp_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer1 = Layer(2, 2)\n",
    "layer2 = Layer(3, 2)\n",
    "layer3 = Layer(1, 3)\n",
    "net = [layer1, layer2, layer3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss is 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 5000 loss is 0.073447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10000 loss is 0.072862\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 15000 loss is 0.072357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20000 loss is 0.071916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 25000 loss is 0.071528\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30000 loss is 0.071184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 35000 loss is 0.070878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40000 loss is 0.070603\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 45000 loss is 0.070354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 50000 loss is 0.070130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 55000 loss is 0.069925\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 60000 loss is 0.069738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 65000 loss is 0.069566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 70000 loss is 0.069408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 75000 loss is 0.069262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 80000 loss is 0.069127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 85000 loss is 0.069001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 90000 loss is 0.068884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 95000 loss is 0.068775\n"
     ]
    }
   ],
   "source": [
    "train(100000, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test result is [[0.618406]]\ntest result is [[2.70503012e-07]]\n"
     ]
    }
   ],
   "source": [
    "test(net, np.array([1,0]))\n",
    "test(net, np.array([0,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
